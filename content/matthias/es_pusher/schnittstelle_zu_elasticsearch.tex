\section{Schnittstelle zu Elasticsearch - Pusher}
Der Pusher Service bildet die Schnittstelle des Backend zur Datenbank.
Als Programmiersprache wurde Golang \cite{go} eingesetzt, mit dessen Standartbibliothek eine REST-API als Schnittstelle für interne Anwendungen bereitgestellt wird.
Die Anbindung der Datenbank wird über die offizielle Bibliothek \texttt{go-elasticsearch}\cite{goes} übernommen.
Um Nutzer möglichts effektiv voneinander zu trennen, wird je ein Index pro Nutzer verwendet.
Es besteht die Möglichkeit über die REST-API ein oder mehrere Dokumente in dem Index von einem oder mehreren Nutzern zu speichern.
Um die Zusammenarbeit mit dem Frontend-Team zu ermöglichen haben wir gemeinsam ein Dokumenten-Format entwickelt, das eindeutig in einem \texttt{Struct} definiert ist:
\begin{minted}{go}
// Document contains the schema of a data entry which is stored in Elasticsearch
type Document struct {
  Created         time.Time `json:"created"`
  Author          string    `json:"author"`
  Title           string    `json:"title"`
  RawContent      string    `json:"raw_content"`
  MarkdownContent string    `json:"markdown_content"`
  PdfURL          string    `json:"pdf"`
  ScreenshotURL   string    `json:"screenshot"`
  ThumbnailURL    string    `json:"thumbnail"`
  URL             string    `json:"url"`
  Categories      []string  `json:"categories"`
  IsFromFeed      bool      `json:"from_feed"`
  FeedURL         string    `json:"feed_url"`
  Starred         bool      `json:"starred"`
  ReadLater       bool      `json:"read_later"`
}
\end{minted}
Während der Entwicklung haben wir erkannt, dass Webseiten oftmals von mehreren RSS Feeds referenziert werden und sich entsprechend mehrfach im Index eines Nutzers.
Um diesem Problem entgegen zu Wirken, wird aus dem Titel und dem Inhalt einer Webseite ein Hashwert gebildet von dem die eindeutige ID in ElasticSearch abgeleitet wird:
\begin{minted}{go}
// Add all documents
for _, d := range docs {

  wg.Add(1)
  go func(d document.Document) {
    // Generate hashed document index to avoid duplicates
    idHasher := sha256.New()
    io.WriteString(idHasher, d.URL+d.Title+d.RawContent)
    dString, _ := d.Dump()
    defer wg.Done()

    for _, index := range indexes {
      wg.Add(1)
      go func(index string) {
        defer wg.Done()
        req := esapi.IndexRequest{
          Index:      index,
          DocumentID: hex.EncodeToString(idHasher.Sum(nil)),
          Body:       strings.NewReader(string(dString)),
          Refresh:    "true",
        }

        // Insert into elasticsearch
        res, err := req.Do(context.Background(), e.es)

        if err != nil || res.IsError() {
          return
        }

        addedDocumentCount.Inc()
      }(index)
    }

  }(d)
}
\end{minted}
